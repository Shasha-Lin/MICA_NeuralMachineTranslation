{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "#from comet_ml import Experiment\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import io\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import subprocess \n",
    "import pickle\n",
    "\n",
    "import socket\n",
    "import visdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Code Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_to_test = \"bpe2char_3_121317__0.000121_1024_15_Bahdanau\"\n",
    "epoch_eval = 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#out_dir = \"/scratch/eff254/NLP/MICA_NeuralMachineTranslation/EduTrials/FinalModels/checkpoints\"\n",
    "#out_dir = \"/scratch/rds491/MICA_NeuralMachineTranslation/EduTrials/FinalModels/checkpoints\" \n",
    "out_dir = \"/scratch/mmd378/NLP_2017/cps_to_eval\"\n",
    "# If running things from Raul, getfacl on his checkpoints AND Evaluation folders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Epoch for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_number(filename):\n",
    "    \n",
    "    number = re.split(\"_\", filename, maxsplit=0, flags=0)[-1]\n",
    "    number = re.split(\"[.]\", number, maxsplit=0, flags=0)[0]\n",
    "    \n",
    "    try: \n",
    "        int(number)\n",
    "        return int(number)\n",
    "    except ValueError:\n",
    "        return 0 # A filter for opt files\n",
    "    \n",
    "def get_max_iteration(): \n",
    "\n",
    "    files = os.listdir(\"{}/{}/\".format(out_dir, model_to_test))\n",
    "    iterations = [get_number(x) for x in files]\n",
    "    \n",
    "    return np.max(iterations)\n",
    "\n",
    "if epoch_eval is not None: \n",
    "    epoch = epoch_eval \n",
    "else: \n",
    "    epoch = get_max_iteration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "opt = pickle.load(open(\"{}/{}/model_opt.p\".format(out_dir, model_to_test), \"rb\"))\n",
    "\n",
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "UNK_token = 3\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\", 3: \"UNK\"}\n",
    "        self.n_words = 4 # Count default tokens\n",
    "\n",
    "    def index_words(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed: return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words %s / %s = %.4f' % (\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\", 3: \"UNK\"}\n",
    "        self.n_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.index_word(word)\n",
    "\n",
    "def read_langs(lang1, lang2, set_type=\"train\", term=\"txt\", reverse=False, normalize=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    if set_type == \"train\":\n",
    "        filename = '%s/train/%s-%s.%s' % (opt.main_data_dir, lang1, lang2, term)\n",
    "    elif set_type == \"dev\":\n",
    "        filename = '%s/dev/%s-%s.%s' % (opt.main_data_dir, lang1, lang2, term)\n",
    "    elif set_type == \"valid\":\n",
    "        filename = '%s/dev/%s-%s.%s' % (opt.main_data_dir, lang1, lang2, term)\n",
    "    elif set_type == \"tst2010\":\n",
    "        filename = '%s/test/%s-%s.tst2010-%s' % (opt.main_data_dir, lang1, lang2, term)\n",
    "    elif set_type == \"tst2011\":\n",
    "        filename = '%s/test/%s-%s.tst2011-%s' % (opt.main_data_dir, lang1, lang2, term)\n",
    "    elif set_type == \"tst2012\":\n",
    "        filename = '%s/test/%s-%s.tst2012-%s' % (opt.main_data_dir, lang1, lang2, term)\n",
    "    elif set_type == \"tst2013\":\n",
    "        filename = '%s/test/%s-%s.tst2013-%s' % (opt.main_data_dir, lang1, lang2, term)\n",
    "    elif set_type == \"tst2014\":\n",
    "        filename = '%s/test/%s-%s.tst2014-%s' % (opt.main_data_dir, lang1, lang2, term)\n",
    "    else:\n",
    "        raise ValueError(\"set_type not found. Check data folder options\")\n",
    "\n",
    "\n",
    "    # lines contains the data in form of a list\n",
    "    lines = open(filename).read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    if normalize == True:\n",
    "        pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "    else:\n",
    "        pairs = [[s for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_lang = pickle.load(open(\"{}/{}/input_lang.p\".format(out_dir, model_to_test), \"rb\"))\n",
    "output_lang = pickle.load(open(\"{}/{}/output_lang.p\".format(out_dir, model_to_test), \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Main model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading/Updating encoder state dict at epoch 6000\n",
      "Loading/Updating decoder state dict at epoch 6000\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "# 3. Main model encoder - decoder #\n",
    "###################################\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size #no of words in the input Language\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=self.dropout, bidirectional=True)\n",
    "\n",
    "\n",
    "    def forward(self, input_seqs, input_lengths, hidden=None): # hidden vector starts with zero (a guess!)\n",
    "\n",
    "        # Note: we run this all at once (over multiple batches of multiple sequences)\n",
    "        embedded = self.embedding(input_seqs) # size = (max_length, batch_size, embed_size). NOTE: embed_size = hidden size here\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths) # size = (max_length * batch_size, embed_size)\n",
    "\n",
    "        outputs, hidden = self.gru(packed, hidden) # outputs are supposed to be probability distribution right?\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs\n",
    "        return outputs, hidden\n",
    "\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        max_len = encoder_outputs.size(0)\n",
    "        this_batch_size = encoder_outputs.size(1)\n",
    "\n",
    "        # Create variable to store attention energies\n",
    "        attn_energies = Variable(torch.zeros(this_batch_size, max_len)) # B x S\n",
    "\n",
    "        if opt.USE_CUDA:\n",
    "            attn_energies = attn_energies.cuda()\n",
    "\n",
    "        # For each batch of encoder outputs\n",
    "        for b in range(this_batch_size):\n",
    "            # Calculate energy for each encoder output\n",
    "            for i in range(max_len):\n",
    "                attn_energies[b, i] = self.score(hidden[b,:], encoder_outputs[i, b])\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x B x S\n",
    "        return F.softmax(attn_energies).unsqueeze(1)\n",
    "\n",
    "    def score(self, hidden, encoder_output):\n",
    "\n",
    "        if self.method == 'dot':\n",
    "            # Used by Luong\n",
    "            energy = hidden.squeeze(0).dot(encoder_output)\n",
    "            return energy\n",
    "\n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            energy = hidden.dot(energy)\n",
    "            return energy\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            # Used by Bahdanau\n",
    "            energy = self.attn(torch.cat((hidden, encoder_output), 0))\n",
    "            energy = (self.v.squeeze(0)).dot(energy)\n",
    "            return energy\n",
    "\n",
    "###############################\n",
    "#  BAHDANAU_ATTN_DECODER_RNN  #\n",
    "###############################\n",
    "\n",
    "class BahdanauAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(BahdanauAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Define parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        ## 3. self.max_length = max_length\n",
    "        ## self.max_length = opt.MAX_LENGTH\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attn = Attn('concat', hidden_size)\n",
    "\n",
    "        # Modifications made below in 2 lines\n",
    "        self.gru = nn.GRU(2*hidden_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        # self.out = nn.Linear(hidden_size * 2, output_size) # use of linear layer ?\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, word_input.data.shape[0], -1) # S=1 x B x N , ## N = hidden size (doubt)\n",
    "        word_embedded = self.dropout(word_embedded)\n",
    "\n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "        attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
    "        context = context.transpose(0, 1) # 1 x B x N\n",
    "\n",
    "        # Combine embedded input word and attended context, run through RNN\n",
    "        rnn_input = torch.cat((word_embedded, context), 2) # 1 x B x 2N (There seems to be a mistake here)\n",
    "        output, hidden = self.gru(rnn_input, last_hidden)\n",
    "\n",
    "        # Final output layer\n",
    "        output = output.squeeze(0) # B x N\n",
    "        output = F.log_softmax(self.out(output))\n",
    "        # output = F.log_softmax(self.out(torch.cat((output, context.squeeze(0)), 1)))\n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "############################\n",
    "#  LUONG_ATTN_DECODER_RNN  #\n",
    "############################\n",
    "\n",
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # Choose attention model\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_seq, last_hidden, encoder_outputs):\n",
    "            # Note: we run this one step at a time\n",
    "\n",
    "            # Get the embedding of the current input word (last output word)\n",
    "            batch_size = input_seq.size(0)\n",
    "            embedded = self.embedding(input_seq)\n",
    "            embedded = self.embedding_dropout(embedded)\n",
    "            embedded = embedded.view(1, batch_size, self.hidden_size) # S=1 x B x N\n",
    "\n",
    "            # Get current hidden state from input word and last hidden state\n",
    "            rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "\n",
    "            # Calculate attention from current RNN state and all encoder outputs;\n",
    "            # apply to encoder outputs to get weighted average \n",
    "\n",
    "            attn_weights = self.attn(rnn_output.transpose(0, 1), encoder_outputs) # B*1*S encoder_outputs: S*B*emb\n",
    "            context = attn_weights.bmm(encoder_outputs.transpose(0, 1)).squeeze(1)\n",
    "            # Attentional vector using the RNN hidden state and context vector\n",
    "            # concatenated together (Luong eq. 5)        \n",
    "            rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "            # context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
    "            concat_input = torch.cat((rnn_output, context), 1)\n",
    "            concat_output = F.tanh(self.concat(concat_input))\n",
    "\n",
    "            # Finally predict next token (Luong eq. 6, without softmax & logsigmoid)\n",
    "            output = F.logsigmoid(self.out(concat_output))\n",
    "\n",
    "            # Return final output, hidden state, and attention weights (for visualization)\n",
    "            return output, hidden, attn_weights\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, opt.hidden_size, opt.n_layers, dropout=opt.dropout)\n",
    "\n",
    "if opt.attention == 'Luong':\n",
    "    decoder = LuongAttnDecoderRNN('dot', opt.hidden_size, output_lang.n_words, opt.n_layers, dropout=opt.dropout)\n",
    "elif opt.attention == 'Bahdanau':\n",
    "    decoder = BahdanauAttnDecoderRNN( opt.hidden_size, output_lang.n_words, opt.n_layers, dropout_p=opt.dropout)\n",
    "else: \n",
    "    raise ValueError('Attention not found: Options are Luong or Bahdanau')   \n",
    "    \n",
    "if opt.USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "print(\"Loading/Updating encoder state dict at epoch {}\".format(epoch))\n",
    "enc_state = torch.load(\"{}/{}/saved_encoder_{}.pth\".format(out_dir, model_to_test, epoch))\n",
    "encoder.load_state_dict(enc_state)\n",
    "\n",
    "print(\"Loading/Updating decoder state dict at epoch {}\".format(epoch))\n",
    "dec_state = torch.load(\"{}/{}/saved_decoder_{}.pth\".format(out_dir, model_to_test, epoch))\n",
    "decoder.load_state_dict(dec_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Valuation framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def indexes_from_sentence(lang, sentence):\n",
    "    try:\n",
    "        val = [lang.word2index[word] for word in sentence.split(' ')]\n",
    "    except KeyError:\n",
    "        # Do it individually. Means one word is not on dictionary:\n",
    "        val = []\n",
    "        for word in sentence.split(' '):\n",
    "            try:\n",
    "                indexed = lang.word2index[word]\n",
    "                val.append(indexed)\n",
    "            except KeyError:\n",
    "                val.append(3)\n",
    "\n",
    "    return val + [EOS_token]\n",
    "\n",
    "def update_dictionary(target_sequence, topv, topi, key, dec_hidden, decoder_attns):\n",
    "    if len(target_sequence) == 0:\n",
    "        for i in range(len(topi)):\n",
    "            target_sequence.update({str(topi[i]) : [topv[i], dec_hidden, decoder_attns] })\n",
    "    else:\n",
    "        prev_val = target_sequence[key][0]\n",
    "        for i in range(len(topi)):\n",
    "            target_sequence.update({key+\"-\"+str(topi[i]) : [topv[i]+prev_val, dec_hidden, decoder_attns] })\n",
    "        del[target_sequence[key]]\n",
    "\n",
    "\n",
    "def get_seq_through_beam_search(max_length, decoder, decoder_input, decoder_hidden, decoder_attentions, encoder_outputs, kmax ):\n",
    "\n",
    "    target_sequence = dict()\n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "\n",
    "        if di == 0:\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder( decoder_input, decoder_hidden, encoder_outputs )\n",
    "            topv, topi = decoder_output.data.topk(kmax)\n",
    "            topv = topv[0].cpu().numpy()\n",
    "            topi = topi[0].cpu().numpy()\n",
    "            decoder_attentions[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "            update_dictionary(target_sequence, topv, topi, None, decoder_hidden, decoder_attentions)\n",
    "        else:\n",
    "            temp = target_sequence.copy()\n",
    "            keys = list(temp.keys())\n",
    "            for i in range(len(keys)):\n",
    "                inp = int(keys[i].split(\"-\")[-1] if len(keys[i]) > 1 else keys[i])\n",
    "                if inp != EOS_token:\n",
    "                    dec_input = Variable(torch.LongTensor([inp]))\n",
    "                    dec_input = dec_input.cuda() if opt.USE_CUDA else dec_input\n",
    "                    decoder_output, dec_hidden, decoder_attention = decoder( dec_input, temp[keys[i]][1], encoder_outputs )\n",
    "                    topv, topi = decoder_output.data.topk(kmax)\n",
    "                    topv = topv[0].cpu().numpy()\n",
    "                    topi = topi[0].cpu().numpy()\n",
    "                    dec_attns = temp[keys[i]][2]\n",
    "                    dec_attns[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "                    update_dictionary(target_sequence, topv, topi, keys[i], dec_hidden, dec_attns)\n",
    "\n",
    "        # Sort the target_Sequence dictionary and keep top k sequences only\n",
    "        target_sequence = dict(sorted(target_sequence.items(), key=lambda x: x[1][0], reverse=True)[:kmax])\n",
    "\n",
    "    # Get the sequence, decoder_attentions with maximum probability\n",
    "    pair = sorted(target_sequence.items(), key=lambda x: x[1][0], reverse=True)[:1][0]\n",
    "    seq = pair[0]\n",
    "    decoder_attentions = pair[1][2]\n",
    "\n",
    "    # Get the decoded words:\n",
    "    decoded_words_indices = seq.split(\"-\")\n",
    "    decoded_words = [output_lang.index2word[int(i)] for i in decoded_words_indices]\n",
    "    if int(decoded_words_indices[-1]) != EOS_token:\n",
    "        decoded_words.append('<EOS>')\n",
    "\n",
    "    return decoded_words, decoder_attentions\n",
    "\n",
    "# Evaluation is mostly the same as training, but there are no targets. Instead we always feed the decoder's predictions back to itself.\n",
    "# Every time it predicts a word, we add it to the output string. If it predicts the EOS token we stop there. We also store the decoder's attention outputs for each step to display later.\n",
    "\n",
    "def evaluate(input_seq):\n",
    "\n",
    "    max_length = len(input_seq.split(' '))\n",
    "\n",
    "    input_lengths = [len(input_seq)]\n",
    "    input_seqs = [indexes_from_sentence(input_lang, input_seq)]\n",
    "    input_batches = Variable(torch.LongTensor(input_seqs), volatile=True).transpose(0, 1)\n",
    "\n",
    "    if opt.USE_CUDA:\n",
    "        input_batches = input_batches.cuda()\n",
    "\n",
    "    # Set to not-training mode to disable dropout\n",
    "    encoder.train(False)\n",
    "    decoder.train(False)\n",
    "\n",
    "    # Run through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = Variable(torch.LongTensor([SOS_token]), volatile=True) # SOS\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "\n",
    "    if opt.USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Store output words and attention states\n",
    "    decoder_attentions = torch.zeros(max_length + 1, max_length + 1)\n",
    "    decoded_words, decoder_attentions = get_seq_through_beam_search(max_length, decoder, decoder_input, decoder_hidden, decoder_attentions, encoder_outputs, opt.kmax )\n",
    "\n",
    "    # Set back to training mode\n",
    "    encoder.train(True)\n",
    "    decoder.train(True)\n",
    "\n",
    "    return decoded_words, decoder_attentions[:len(decoded_words)+1, :len(encoder_outputs)]\n",
    "\n",
    "# We can evaluate random sentences from the training set and print out the input, target, and output to make some subjective quality judgements:\n",
    "def evaluate_randomly(pairs2eval):\n",
    "    [input_sentence, target_sentence] = random.choice(pairs2eval)\n",
    "    evaluate_and_show_attention(input_sentence, target_sentence)\n",
    "\n",
    "def evaluate_and_show_attention(input_sentence, target_sentence=None):\n",
    "    output_words, attentions = evaluate(input_sentence)\n",
    "\n",
    "    # Calculating the bleu score excluding the last word (<EOS>)\n",
    "    #bleu_score = nltk.translate.bleu_score.sentence_bleu([target_sentence], ' '.join(output_words[:-1]))\n",
    "\n",
    "    output_sentence = ' '.join(output_words)\n",
    "\n",
    "    print('>', input_sentence)\n",
    "    if target_sentence is not None:\n",
    "        print('=', target_sentence)\n",
    "    print('<', output_sentence)\n",
    "    #print(\"BLUE SCORE IS:\", bleu_score)   \n",
    "\n",
    "def undo_chars(string): \n",
    "    \n",
    "    string = re.sub(\"   \", \"@\", string)\n",
    "    string = re.sub(\" \", \"\", string)\n",
    "    string = re.sub(\"@\", \" \", string)\n",
    "        \n",
    "    return string\n",
    "\n",
    "def undo_bpe(string): \n",
    "    \n",
    "    string = re.sub(\"@@ \", \"\", string)\n",
    "        \n",
    "    return string\n",
    "    \n",
    "def eval_single(string):\n",
    "    \n",
    "    words, tensor = evaluate(string)\n",
    "    words = ' '.join(words)\n",
    "    words = re.sub('<EOS>', '', words)\n",
    "\n",
    "    return(words)    \n",
    "    \n",
    "\n",
    "def evaluate_list_pairs(list_strings, term=opt.model_type):\n",
    "    \n",
    "    if term == \"bpe2bpe\":\n",
    "        output = [undo_bpe(eval_single(x[0])) for x in list_strings]\n",
    "    elif term in [\"bpe2char\", \"bpe2char_2\", \"bpe2char_3\"]:\n",
    "        output = [undo_chars(eval_single(x[0])) for x in list_strings]\n",
    "    else:\n",
    "        output = [eval_single(x[0]) for x in list_strings]\n",
    "    \n",
    "    return output\n",
    "\n",
    "def export_as_list(original, translations): \n",
    "    \n",
    "    with open(\"{}/{}/original_tst.txt\".format(opt.eval_dir, opt.experiment), 'w') as original_file:\n",
    "        for sentence in original:\n",
    "            original_file.write(sentence + \"\\n\")\n",
    "    \n",
    "    \n",
    "    with open(\"{}/{}/translations_tst.txt\".format(opt.eval_dir, opt.experiment), 'w') as translations_file:\n",
    "        for sentence in translations:\n",
    "            translations_file.write(sentence + \"\\n\")\n",
    "        \n",
    "def run_perl(): \n",
    "    \n",
    "    ''' Assumes the multi-bleu.perl is in opt.eval_dir\n",
    "        Assumes you exported files with names in export_as_list()'''\n",
    "    \n",
    "    cmd = \"%s %s < %s\" % (opt.eval_dir + \"./multi-bleu.perl\", opt.eval_dir + opt.experiment + \\\n",
    "        '/original_tst.txt', opt.eval_dir + opt.experiment + '/translations_tst.txt')\n",
    "    bleu_output = subprocess.check_output(cmd, shell=True)\n",
    "    m = re.search(\"BLEU = (.+?),\", str(bleu_output))\n",
    "    bleu_score = float(m.group(1))\n",
    "    \n",
    "    return bleu_score\n",
    "\n",
    "    \n",
    "def multi_blue_dev(dev_pairs, term=opt.model_type):\n",
    "    \n",
    "    prediction = evaluate_list_pairs(dev_pairs)\n",
    "    \n",
    "    if term == \"bpe2bpe\":\n",
    "        target_eval = [undo_bpe(x[1]) for x in dev_pairs]   \n",
    "    elif term in [\"bpe2char\", \"bpe2char_2\", \"bpe2char_3\"]:\n",
    "        target_eval = [undo_chars(x[1]) for x in dev_pairs]   \n",
    "    else:\n",
    "        target_eval = [x[1] for x in dev_pairs] \n",
    "    \n",
    "    export_as_list(target_eval, prediction)\n",
    "    blue = run_perl()\n",
    "    return blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Attention visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Reading lines...\n",
      "Reading lines...\n"
     ]
    }
   ],
   "source": [
    "test2012 = read_langs(\"en\", \"fr\", set_type=\"tst2012\", term=\"bpe2bpe\")\n",
    "test2013 = read_langs(\"en\", \"fr\", set_type=\"tst2013\", term=\"bpe2bpe\")\n",
    "test2014 = read_langs(\"en\", \"fr\", set_type=\"tst2014\", term=\"bpe2bpe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    \"\"\"\n",
    "    Function that takes in attention and visualize the attention.\n",
    "    @param - input_sentence: string the represent a list of words from source language\n",
    "    @param - output_words: the gold translation in target language\n",
    "    @param - attentions: a numpy array\n",
    "    \"\"\"\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_pair):\n",
    "    output_words, attentions = evaluate(input_pair[0])\n",
    "    print('input =', input_pair[0])\n",
    "    print('reference = ', input_pair[1])\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_pair[0], output_words, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = The most important thing is passion .\n",
      "reference =  Le plus important , c&apos; est la passion .\n",
      "output = L e   p r o <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAAElCAYAAACRXOt+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b35fef74a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluateAndShowAttention(test2013[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = There &apos;s only one thing that all the successful companies in the world have in common , only one : None were started by one person .\n",
      "reference =  Toutes les sociétés qui réussissent dans le monde n&apos; ont qu&apos; une seule chose en commun , une seule chose : Aucune n&apos; ait été lancée par une seule personne .\n",
      "output = I l   y   e n   a v a i t   q u e l q u e s  <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAAEqCAYAAABgClmrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHzPXKFJ0yedkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b36e1a79c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluateAndShowAttention(test2013[111])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
