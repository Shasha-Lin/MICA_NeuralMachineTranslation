{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "#from comet_ml import Experiment\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import io\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import subprocess \n",
    "import pickle\n",
    "\n",
    "import socket\n",
    "import visdom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Code Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model_to_test = \"bpe2char_3_121417__0.0008_256_5_Luong\"\n",
    "epoch_eval = 12600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#out_dir = \"/scratch/eff254/NLP/MICA_NeuralMachineTranslation/EduTrials/FinalModels/checkpoints\"\n",
    "#out_dir = \"/scratch/rds491/MICA_NeuralMachineTranslation/EduTrials/FinalModels/checkpoints\" \n",
    "out_dir = \"/scratch/mmd378/NLP_2017/cps_to_eval\"\n",
    "# If running things from Raul, getfacl on his checkpoints AND Evaluation folders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Epoch for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_number(filename):\n",
    "    \n",
    "    number = re.split(\"_\", filename, maxsplit=0, flags=0)[-1]\n",
    "    number = re.split(\"[.]\", number, maxsplit=0, flags=0)[0]\n",
    "    \n",
    "    try: \n",
    "        int(number)\n",
    "        return int(number)\n",
    "    except ValueError:\n",
    "        return 0 # A filter for opt files\n",
    "    \n",
    "def get_max_iteration(): \n",
    "\n",
    "    files = os.listdir(\"{}/{}/\".format(out_dir, model_to_test))\n",
    "    iterations = [get_number(x) for x in files]\n",
    "    \n",
    "    return np.max(iterations)\n",
    "\n",
    "if epoch_eval is not None: \n",
    "    epoch = epoch_eval \n",
    "else: \n",
    "    epoch = get_max_iteration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "opt = pickle.load(open(\"{}/{}/model_opt.p\".format(out_dir, model_to_test), \"rb\"))\n",
    "\n",
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "UNK_token = 3\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\", 3: \"UNK\"}\n",
    "        self.n_words = 4 # Count default tokens\n",
    "\n",
    "    def index_words(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.index_word(word)\n",
    "\n",
    "    def index_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "    # Remove words below a certain count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed: return\n",
    "        self.trimmed = True\n",
    "\n",
    "        keep_words = []\n",
    "\n",
    "        for k, v in self.word2count.items():\n",
    "            if v >= min_count:\n",
    "                keep_words.append(k)\n",
    "\n",
    "        print('keep_words %s / %s = %.4f' % (\n",
    "            len(keep_words), len(self.word2index), len(keep_words) / len(self.word2index)\n",
    "        ))\n",
    "\n",
    "        # Reinitialize dictionaries\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"PAD\", 1: \"SOS\", 2: \"EOS\", 3: \"UNK\"}\n",
    "        self.n_words = 3 # Count default tokens\n",
    "\n",
    "        for word in keep_words:\n",
    "            self.index_word(word)\n",
    "\n",
    "def read_langs(lang1, lang2, set_type=\"train\", term=\"txt\", reverse=False, normalize=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    if set_type == \"train\":\n",
    "        filename = '%s/train/%s-%s.%s' % (opt.main_data_dir, lang1, lang2, term)\n",
    "    elif set_type == \"dev\":\n",
    "        filename = '%s/dev/%s-%s.%s' % (opt.main_data_dir, lang1, lang2, term)\n",
    "    elif set_type == \"valid\":\n",
    "        filename = '%s/dev/%s-%s.%s' % (opt.main_data_dir, lang1, lang2, term)\n",
    "    elif set_type == \"tst2010\":\n",
    "        filename = '%s/test/%s-%s.tst2010-%s' % (opt.main_data_dir, lang1, lang2, term)\n",
    "    elif set_type == \"tst2011\":\n",
    "        filename = '%s/test/%s-%s.tst2011-%s' % (opt.main_data_dir, lang1, lang2, term)\n",
    "    elif set_type == \"tst2012\":\n",
    "        filename = '%s/test/%s-%s.tst2012-%s' % (opt.main_data_dir, lang1, lang2, term)\n",
    "    elif set_type == \"tst2013\":\n",
    "        filename = '%s/test/%s-%s.tst2013-%s' % (opt.main_data_dir, lang1, lang2, term)\n",
    "    elif set_type == \"tst2014\":\n",
    "        filename = '%s/test/%s-%s.tst2014-%s' % (opt.main_data_dir, lang1, lang2, term)\n",
    "    else:\n",
    "        raise ValueError(\"set_type not found. Check data folder options\")\n",
    "\n",
    "\n",
    "    # lines contains the data in form of a list\n",
    "    lines = open(filename).read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    if normalize == True:\n",
    "        pairs = [[normalize_string(s) for s in l.split('\\t')] for l in lines]\n",
    "    else:\n",
    "        pairs = [[s for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "input_lang = pickle.load(open(\"{}/{}/input_lang.p\".format(out_dir, model_to_test), \"rb\"))\n",
    "output_lang = pickle.load(open(\"{}/{}/output_lang.p\".format(out_dir, model_to_test), \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Main model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading/Updating encoder state dict at epoch 12600\n",
      "Loading/Updating decoder state dict at epoch 12600\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "# 3. Main model encoder - decoder #\n",
    "###################################\n",
    "\n",
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, dropout=0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "\n",
    "        self.input_size = input_size #no of words in the input Language\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=self.dropout, bidirectional=True)\n",
    "\n",
    "\n",
    "    def forward(self, input_seqs, input_lengths, hidden=None): # hidden vector starts with zero (a guess!)\n",
    "\n",
    "        # Note: we run this all at once (over multiple batches of multiple sequences)\n",
    "        embedded = self.embedding(input_seqs) # size = (max_length, batch_size, embed_size). NOTE: embed_size = hidden size here\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths) # size = (max_length * batch_size, embed_size)\n",
    "\n",
    "        outputs, hidden = self.gru(packed, hidden) # outputs are supposed to be probability distribution right?\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:] # Sum bidirectional outputs\n",
    "        return outputs, hidden\n",
    "\n",
    "class Attn(nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "\n",
    "        self.method = method\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        if self.method == 'general':\n",
    "            self.attn = nn.Linear(self.hidden_size, hidden_size)\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = nn.Parameter(torch.FloatTensor(1, hidden_size))\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        max_len = encoder_outputs.size(0)\n",
    "        this_batch_size = encoder_outputs.size(1)\n",
    "\n",
    "        # Create variable to store attention energies\n",
    "        attn_energies = Variable(torch.zeros(this_batch_size, max_len)) # B x S\n",
    "\n",
    "        if opt.USE_CUDA:\n",
    "            attn_energies = attn_energies.cuda()\n",
    "\n",
    "        # For each batch of encoder outputs\n",
    "        for b in range(this_batch_size):\n",
    "            # Calculate energy for each encoder output\n",
    "            for i in range(max_len):\n",
    "                attn_energies[b, i] = self.score(hidden[b,:], encoder_outputs[i, b])\n",
    "\n",
    "        # Normalize energies to weights in range 0 to 1, resize to 1 x B x S\n",
    "        return F.softmax(attn_energies).unsqueeze(1)\n",
    "\n",
    "    def score(self, hidden, encoder_output):\n",
    "\n",
    "        if self.method == 'dot':\n",
    "            # Used by Luong\n",
    "            energy = hidden.squeeze(0).dot(encoder_output)\n",
    "            return energy\n",
    "\n",
    "        elif self.method == 'general':\n",
    "            energy = self.attn(encoder_output)\n",
    "            energy = hidden.dot(energy)\n",
    "            return energy\n",
    "\n",
    "        elif self.method == 'concat':\n",
    "            # Used by Bahdanau\n",
    "            energy = self.attn(torch.cat((hidden, encoder_output), 0))\n",
    "            energy = (self.v.squeeze(0)).dot(energy)\n",
    "            return energy\n",
    "\n",
    "###############################\n",
    "#  BAHDANAU_ATTN_DECODER_RNN  #\n",
    "###############################\n",
    "\n",
    "class BahdanauAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1):\n",
    "        super(BahdanauAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Define parameters\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        ## 3. self.max_length = max_length\n",
    "        ## self.max_length = opt.MAX_LENGTH\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.attn = Attn('concat', hidden_size)\n",
    "\n",
    "        # Modifications made below in 2 lines\n",
    "        self.gru = nn.GRU(2*hidden_size, hidden_size, n_layers, dropout=dropout_p)\n",
    "        # self.out = nn.Linear(hidden_size * 2, output_size) # use of linear layer ?\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, word_input, last_hidden, encoder_outputs):\n",
    "\n",
    "        # Get the embedding of the current input word (last output word)\n",
    "        word_embedded = self.embedding(word_input).view(1, word_input.data.shape[0], -1) # S=1 x B x N , ## N = hidden size (doubt)\n",
    "        word_embedded = self.dropout(word_embedded)\n",
    "\n",
    "        # Calculate attention weights and apply to encoder outputs\n",
    "        attn_weights = self.attn(last_hidden[-1], encoder_outputs)\n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) # B x 1 x N\n",
    "        context = context.transpose(0, 1) # 1 x B x N\n",
    "\n",
    "        # Combine embedded input word and attended context, run through RNN\n",
    "        rnn_input = torch.cat((word_embedded, context), 2) # 1 x B x 2N (There seems to be a mistake here)\n",
    "        output, hidden = self.gru(rnn_input, last_hidden)\n",
    "\n",
    "        # Final output layer\n",
    "        output = output.squeeze(0) # B x N\n",
    "        output = F.log_softmax(self.out(output))\n",
    "        # output = F.log_softmax(self.out(torch.cat((output, context.squeeze(0)), 1)))\n",
    "        # Return final output, hidden state, and attention weights (for visualization)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "############################\n",
    "#  LUONG_ATTN_DECODER_RNN  #\n",
    "############################\n",
    "\n",
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, attn_model, hidden_size, output_size, n_layers=1, dropout=0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "\n",
    "        # Keep for reference\n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        # Choose attention model\n",
    "        if attn_model != 'none':\n",
    "            self.attn = Attn(attn_model, hidden_size)\n",
    "\n",
    "    def forward(self, input_seq, last_hidden, encoder_outputs):\n",
    "            # Note: we run this one step at a time\n",
    "\n",
    "            # Get the embedding of the current input word (last output word)\n",
    "            batch_size = input_seq.size(0)\n",
    "            embedded = self.embedding(input_seq)\n",
    "            embedded = self.embedding_dropout(embedded)\n",
    "            embedded = embedded.view(1, batch_size, self.hidden_size) # S=1 x B x N\n",
    "\n",
    "            # Get current hidden state from input word and last hidden state\n",
    "            rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "\n",
    "            # Calculate attention from current RNN state and all encoder outputs;\n",
    "            # apply to encoder outputs to get weighted average \n",
    "\n",
    "            attn_weights = self.attn(rnn_output.transpose(0, 1), encoder_outputs) # B*1*S encoder_outputs: S*B*emb\n",
    "            context = attn_weights.bmm(encoder_outputs.transpose(0, 1)).squeeze(1)\n",
    "            # Attentional vector using the RNN hidden state and context vector\n",
    "            # concatenated together (Luong eq. 5)        \n",
    "            rnn_output = rnn_output.squeeze(0) # S=1 x B x N -> B x N\n",
    "            # context = context.squeeze(1)       # B x S=1 x N -> B x N\n",
    "            concat_input = torch.cat((rnn_output, context), 1)\n",
    "            concat_output = F.tanh(self.concat(concat_input))\n",
    "\n",
    "            # Finally predict next token (Luong eq. 6, without softmax & logsigmoid)\n",
    "            output = F.logsigmoid(self.out(concat_output))\n",
    "\n",
    "            # Return final output, hidden state, and attention weights (for visualization)\n",
    "            return output, hidden, attn_weights\n",
    "\n",
    "encoder = EncoderRNN(input_lang.n_words, opt.hidden_size, opt.n_layers, dropout=opt.dropout)\n",
    "\n",
    "if opt.attention == 'Luong':\n",
    "    decoder = LuongAttnDecoderRNN('dot', opt.hidden_size, output_lang.n_words, opt.n_layers, dropout=opt.dropout)\n",
    "elif opt.attention == 'Bahdanau':\n",
    "    decoder = BahdanauAttnDecoderRNN( opt.hidden_size, output_lang.n_words, opt.n_layers, dropout_p=opt.dropout)\n",
    "else: \n",
    "    raise ValueError('Attention not found: Options are Luong or Bahdanau')   \n",
    "    \n",
    "if opt.USE_CUDA:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "\n",
    "print(\"Loading/Updating encoder state dict at epoch {}\".format(epoch))\n",
    "enc_state = torch.load(\"{}/{}/saved_encoder_{}.pth\".format(out_dir, model_to_test, epoch))\n",
    "encoder.load_state_dict(enc_state)\n",
    "\n",
    "print(\"Loading/Updating decoder state dict at epoch {}\".format(epoch))\n",
    "dec_state = torch.load(\"{}/{}/saved_decoder_{}.pth\".format(out_dir, model_to_test, epoch))\n",
    "decoder.load_state_dict(dec_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Valuation framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def indexes_from_sentence(lang, sentence):\n",
    "    try:\n",
    "        val = [lang.word2index[word] for word in sentence.split(' ')]\n",
    "    except KeyError:\n",
    "        # Do it individually. Means one word is not on dictionary:\n",
    "        val = []\n",
    "        for word in sentence.split(' '):\n",
    "            try:\n",
    "                indexed = lang.word2index[word]\n",
    "                val.append(indexed)\n",
    "            except KeyError:\n",
    "                val.append(3)\n",
    "\n",
    "    return val + [EOS_token]\n",
    "\n",
    "def update_dictionary(target_sequence, topv, topi, key, dec_hidden, decoder_attns):\n",
    "    if len(target_sequence) == 0:\n",
    "        for i in range(len(topi)):\n",
    "            target_sequence.update({str(topi[i]) : [topv[i], dec_hidden, decoder_attns] })\n",
    "    else:\n",
    "        prev_val = target_sequence[key][0]\n",
    "        for i in range(len(topi)):\n",
    "            target_sequence.update({key+\"-\"+str(topi[i]) : [topv[i]+prev_val, dec_hidden, decoder_attns] })\n",
    "        del[target_sequence[key]]\n",
    "\n",
    "\n",
    "def get_seq_through_beam_search(max_length, decoder, decoder_input, decoder_hidden, decoder_attentions, encoder_outputs, kmax ):\n",
    "\n",
    "    target_sequence = dict()\n",
    "    # Run through decoder\n",
    "    for di in range(max_length):\n",
    "\n",
    "        if di == 0:\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder( decoder_input, decoder_hidden, encoder_outputs )\n",
    "            topv, topi = decoder_output.data.topk(kmax)\n",
    "            topv = topv[0].cpu().numpy()\n",
    "            topi = topi[0].cpu().numpy()\n",
    "            decoder_attentions[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "            update_dictionary(target_sequence, topv, topi, None, decoder_hidden, decoder_attentions)\n",
    "        else:\n",
    "            temp = target_sequence.copy()\n",
    "            keys = list(temp.keys())\n",
    "            for i in range(len(keys)):\n",
    "                inp = int(keys[i].split(\"-\")[-1] if len(keys[i]) > 1 else keys[i])\n",
    "                if inp != EOS_token:\n",
    "                    dec_input = Variable(torch.LongTensor([inp]))\n",
    "                    dec_input = dec_input.cuda() if opt.USE_CUDA else dec_input\n",
    "                    decoder_output, dec_hidden, decoder_attention = decoder( dec_input, temp[keys[i]][1], encoder_outputs )\n",
    "                    topv, topi = decoder_output.data.topk(kmax)\n",
    "                    topv = topv[0].cpu().numpy()\n",
    "                    topi = topi[0].cpu().numpy()\n",
    "                    dec_attns = temp[keys[i]][2]\n",
    "                    dec_attns[di,:decoder_attention.size(2)] += decoder_attention.squeeze(0).squeeze(0).cpu().data\n",
    "                    update_dictionary(target_sequence, topv, topi, keys[i], dec_hidden, dec_attns)\n",
    "\n",
    "        # Sort the target_Sequence dictionary and keep top k sequences only\n",
    "        target_sequence = dict(sorted(target_sequence.items(), key=lambda x: x[1][0], reverse=True)[:kmax])\n",
    "\n",
    "    # Get the sequence, decoder_attentions with maximum probability\n",
    "    pair = sorted(target_sequence.items(), key=lambda x: x[1][0], reverse=True)[:1][0]\n",
    "    seq = pair[0]\n",
    "    decoder_attentions = pair[1][2]\n",
    "\n",
    "    # Get the decoded words:\n",
    "    decoded_words_indices = seq.split(\"-\")\n",
    "    decoded_words = [output_lang.index2word[int(i)] for i in decoded_words_indices]\n",
    "    if int(decoded_words_indices[-1]) != EOS_token:\n",
    "        decoded_words.append('<EOS>')\n",
    "\n",
    "    return decoded_words, decoder_attentions\n",
    "\n",
    "# Evaluation is mostly the same as training, but there are no targets. Instead we always feed the decoder's predictions back to itself.\n",
    "# Every time it predicts a word, we add it to the output string. If it predicts the EOS token we stop there. We also store the decoder's attention outputs for each step to display later.\n",
    "\n",
    "def evaluate(input_seq):\n",
    "\n",
    "    max_length = len(input_seq.split(' '))\n",
    "\n",
    "    input_lengths = [len(input_seq)]\n",
    "    input_seqs = [indexes_from_sentence(input_lang, input_seq)]\n",
    "    input_batches = Variable(torch.LongTensor(input_seqs), volatile=True).transpose(0, 1)\n",
    "\n",
    "    if opt.USE_CUDA:\n",
    "        input_batches = input_batches.cuda()\n",
    "\n",
    "    # Set to not-training mode to disable dropout\n",
    "    encoder.train(False)\n",
    "    decoder.train(False)\n",
    "\n",
    "    # Run through encoder\n",
    "    encoder_outputs, encoder_hidden = encoder(input_batches, input_lengths, None)\n",
    "\n",
    "    # Create starting vectors for decoder\n",
    "    decoder_input = Variable(torch.LongTensor([SOS_token]), volatile=True) # SOS\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers] # Use last (forward) hidden state from encoder\n",
    "\n",
    "    if opt.USE_CUDA:\n",
    "        decoder_input = decoder_input.cuda()\n",
    "\n",
    "    # Store output words and attention states\n",
    "    decoder_attentions = torch.zeros(max_length + 1, max_length + 1)\n",
    "    decoded_words, decoder_attentions = get_seq_through_beam_search(max_length, decoder, decoder_input, decoder_hidden, decoder_attentions, encoder_outputs, opt.kmax )\n",
    "\n",
    "    # Set back to training mode\n",
    "    encoder.train(True)\n",
    "    decoder.train(True)\n",
    "\n",
    "    return decoded_words, decoder_attentions[:len(decoded_words)+1, :len(encoder_outputs)]\n",
    "\n",
    "# We can evaluate random sentences from the training set and print out the input, target, and output to make some subjective quality judgements:\n",
    "def evaluate_randomly(pairs2eval):\n",
    "    [input_sentence, target_sentence] = random.choice(pairs2eval)\n",
    "    evaluate_and_show_attention(input_sentence, target_sentence)\n",
    "\n",
    "def evaluate_and_show_attention(input_sentence, target_sentence=None):\n",
    "    output_words, attentions = evaluate(input_sentence)\n",
    "\n",
    "    # Calculating the bleu score excluding the last word (<EOS>)\n",
    "    #bleu_score = nltk.translate.bleu_score.sentence_bleu([target_sentence], ' '.join(output_words[:-1]))\n",
    "\n",
    "    output_sentence = ' '.join(output_words)\n",
    "\n",
    "    print('>', input_sentence)\n",
    "    if target_sentence is not None:\n",
    "        print('=', target_sentence)\n",
    "    print('<', output_sentence)\n",
    "    #print(\"BLUE SCORE IS:\", bleu_score)   \n",
    "\n",
    "def undo_chars(string): \n",
    "    \n",
    "    string = re.sub(\"   \", \"@\", string)\n",
    "    string = re.sub(\" \", \"\", string)\n",
    "    string = re.sub(\"@\", \" \", string)\n",
    "        \n",
    "    return string\n",
    "\n",
    "def undo_bpe(string): \n",
    "    \n",
    "    string = re.sub(\"@@ \", \"\", string)\n",
    "        \n",
    "    return string\n",
    "    \n",
    "def eval_single(string):\n",
    "    \n",
    "    words, tensor = evaluate(string)\n",
    "    words = ' '.join(words)\n",
    "    words = re.sub('<EOS>', '', words)\n",
    "\n",
    "    return(words)    \n",
    "    \n",
    "\n",
    "def evaluate_list_pairs(list_strings, term=opt.model_type):\n",
    "    \n",
    "    if term == \"bpe2bpe\":\n",
    "        output = [undo_bpe(eval_single(x[0])) for x in list_strings]\n",
    "    elif term in [\"bpe2char\", \"bpe2char_2\", \"bpe2char_3\"]:\n",
    "        output = [undo_chars(eval_single(x[0])) for x in list_strings]\n",
    "    else:\n",
    "        output = [eval_single(x[0]) for x in list_strings]\n",
    "    \n",
    "    return output\n",
    "\n",
    "def export_as_list(original, translations): \n",
    "    \n",
    "    with open(\"{}/{}/original_tst.txt\".format(opt.eval_dir, opt.experiment), 'w') as original_file:\n",
    "        for sentence in original:\n",
    "            original_file.write(sentence + \"\\n\")\n",
    "    \n",
    "    \n",
    "    with open(\"{}/{}/translations_tst.txt\".format(opt.eval_dir, opt.experiment), 'w') as translations_file:\n",
    "        for sentence in translations:\n",
    "            translations_file.write(sentence + \"\\n\")\n",
    "        \n",
    "def run_perl(): \n",
    "    \n",
    "    ''' Assumes the multi-bleu.perl is in opt.eval_dir\n",
    "        Assumes you exported files with names in export_as_list()'''\n",
    "    \n",
    "    cmd = \"%s %s < %s\" % (opt.eval_dir + \"./multi-bleu.perl\", opt.eval_dir + opt.experiment + \\\n",
    "        '/original_tst.txt', opt.eval_dir + opt.experiment + '/translations_tst.txt')\n",
    "    bleu_output = subprocess.check_output(cmd, shell=True)\n",
    "    m = re.search(\"BLEU = (.+?),\", str(bleu_output))\n",
    "    bleu_score = float(m.group(1))\n",
    "    \n",
    "    return bleu_score\n",
    "\n",
    "    \n",
    "def multi_blue_dev(dev_pairs, term=opt.model_type):\n",
    "    \n",
    "    prediction = evaluate_list_pairs(dev_pairs)\n",
    "    \n",
    "    if term == \"bpe2bpe\":\n",
    "        target_eval = [undo_bpe(x[1]) for x in dev_pairs]   \n",
    "    elif term in [\"bpe2char\", \"bpe2char_2\", \"bpe2char_3\"]:\n",
    "        target_eval = [undo_chars(x[1]) for x in dev_pairs]   \n",
    "    else:\n",
    "        target_eval = [x[1] for x in dev_pairs] \n",
    "    \n",
    "    export_as_list(target_eval, prediction)\n",
    "    blue = run_perl()\n",
    "    return blue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Attention visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Reading lines...\n",
      "Reading lines...\n"
     ]
    }
   ],
   "source": [
    "test2012 = read_langs(\"en\", \"fr\", set_type=\"tst2012\", term=opt.model_type)\n",
    "test2013 = read_langs(\"en\", \"fr\", set_type=\"tst2013\", term=opt.model_type)\n",
    "test2014 = read_langs(\"en\", \"fr\", set_type=\"tst2014\", term=opt.model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    \"\"\"\n",
    "    Function that takes in attention and visualize the attention.\n",
    "    @param - input_sentence: string the represent a list of words from source language\n",
    "    @param - output_words: the gold translation in target language\n",
    "    @param - attentions: a numpy array\n",
    "    \"\"\"\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_pair):\n",
    "    output_words, attentions = evaluate(input_pair[0])\n",
    "    print('input =', input_pair[0])\n",
    "    print('reference = ', input_pair[1])\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_pair[0], output_words, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = The most important thing is passion .\n",
      "reference =  L e   p l u s   i m p o r t a n t ,   c ' e s t   l a   p a s s i o n . \n",
      "output = L a   p l u <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUYAAAElCAYAAACYt0sEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ba42eb99630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluateAndShowAttention(test2013[45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = There &apos;s only one thing that all the successful companies in the world have in common , only one : None were started by one person .\n",
      "reference =  T o u t e s   l e s   s o c i é t é s   q u i   r é u s s i s s e n t   d a n s   l e   m o n d e   n ' o n t   q u ' u n e   s e u l e   c h o s e   e n   c o m m u n ,   u n e   s e u l e   c h o s e :   A u c u n e   n ' a i t   é t é   l a n c é e   p a r   u n e   s e u l e   p e r s o n n e . \n",
      "output = I l   n ' y   a v a i t   j u s t e   q u e  <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATwAAAEqCAYAAACIiuyAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztnXm8HFWZv59vQkgCJGwBBYzsiCRggKhoUDZRlEUFBFkc\nRB0YxJ/ouOLg8gN1RHFDZdhkRwdUYFAGARliWIWEBBLCOsgqCgmBhC0kue/8cU5z63a6qut2173V\n1f0+91Of21XvqXPequp+6yzveY/MDMdxnF5gRNkKOI7jDBdu8BzH6Rnc4DmO0zO4wXMcp2dwg+c4\nTs/gBs9xnJ7BDZ7jOD2DGzzHcXoGN3g9gKRpklaPnw+X9CNJG5etl+MMN27weoP/AF6S9BbgC8D/\nAheUq5LjDD+rlK2A0x6SdsiSm9mdwHIzM0kfBH5uZr+U9Mnh0dBxOgc3eNXnhxkyA3YHlkg6HvgY\n8C5JI4BRw6Gc43QS8uAB3Y+k1wOHAneY2Y2S3gjsamberHV6Cjd4XYKkf2p0vGbU4iDFlmb2J0mr\nASPNbMlw6ug4ZeNN2u7hrYnPY4A9gDuBCyT9M3AUsA6wObARcHpM4zg9g9fwuhRJawH/aWZ7SZoD\nvA34i5ltH+VzzWzbUpV0nGHG3VK6lxeBTePnpWb2ak0gaRXCgIbj9BTepO0SJP2efiM2AtgGuDTu\n/1nS14CxkvYEPg38fvi1dJxy8SZtxZE02syWStolcXg58KiZPRHTjAA+CbwXEHANcLb5w3d6DDd4\nFUfSnWa2g6QLzexjZeszFEjaCNiYRIvEzGaUp5FTVbxJW31WlXQo8E5J+9fJvmBm0yTNpUGfnZlt\nNywatoGkk4GDgfnAinjYADd4zqBxg1d9/gU4DFgL2LdO9lj8v8+walQsHwLeZGZLy1bEqT49ZfAk\nbQ48Efu8dgW2Ay4ws+fK1ax1zOwm4CZJM83slylpHh1mtYrkYcI0ODd4Ttv0mlvK74AVkrYAzgQm\nAr8qV6XCWCxpHICkEyRdJqnmc7e/pAclPS9psaQlkhaXq25uXgLmSDpD0qm1rWylnGrSUzU8oM/M\nlkv6MPAzM/uZpNllK1UQXzez30jaGXgP8APCbIq3A98H9jWze8tUsEWujJvjtE2vGbxlkg4BjqC/\nv6tboobUOvT3Bs40s6skfTse+0dFjR1mdr6kVYGt4qH7zWxZmTo51aXXDN6RhE7+75jZXyVtClxY\nsk5F8aSkM4A9gZMljaa/y2KmpEuAK0j0hZnZZcOv5uCIfa3nA48QfAgnSjrC3VKGHkkCLgeOr+oL\nsx73w+sSYgSUvYC5ZvagpA2Abc3sWknnNjjFzOwTw6vl4JE0CzjUzO6P+1sBvzazHcvVrDXSXIRq\ndJKrkKT3AecQ5mR/oWx9iqCnDJ6kb5nZtxL73wWeJ8w6WFiaYgXQjSPQAJLurjcCjY5VhcRaIsfG\n/7UWxmEAZvbVAstqy2Fb0qXAucBPgW3MbHlRupVFrxm8fc3s94n9DxHCJb3FzBrGk6sKMSLKVGAT\n4L+B/wImmdkHJI0hTC2bRAgdBUBFanjnAH3ARfHQYYRYfh2vexaSZtci1ySO3WlmmSH7B5F/Q4dt\nM9sv5/kTgD+b2SRJpwH/Y2a/LUK3MumpPryksYv7V5SlyxBQG4Hen5VHoC8E7gPeB5xIMBpV6ZM5\nhlAb+mzcvxE4rTx1CkOSppnZzXHnnRTrJtauw/bHgF/Hz+cCJwGVN3iYWc9sBPeM8YSR2euBZ4DD\ny9aroGv7C3AIMA/YNB6bF//Pjv/vjv9HAbeVrXMvb8COwF2EwZhHgDnADgXmfzWwRhvnzwU2Suzf\nBUws+761u3VdDU/SWOCNFju563ivmX05+uE9AuxPmJN5UYO0VSNrBLrmxvGcpMnA34H1S9Bx0Eja\nh1C7qPVFidA0G1+qYm1iZrOAt0haM+4/X3ARNYft6xk4Mv/Z9FMCMXjsz83sycThLwITgMcL1nNY\n6ao+PEn7AqcAq5rZppKmACda7LeQNM/MJks6G/itmf1R0l1m9pYy9S6KNGMv6VOEWSbbEZonaxAc\nlc8Yfi0Hh6SHCC+mudZFX1ZJrwO+C2xoZu+XtA3wDkuZHthC/kc0Om5m5xeRf2Upu4pZ5AbMAtYk\nNuFqVfPE5+8R+rJmE5p16xHCnpeuewHXvi9wP/DXuD8FuLJsvQq4runAiLL1GILruho4CLgr7q+S\n/K4WVMaqwOS4jcp5zj8TFnuCUJs+F1gM3A1sX/Z9a3frtibtMjN7PvhLvsZrtQIz+6qk7wPPm9kK\nSS8CHxxuJYeIbxHWrZgOYGZzJG0GIGndKJ9GuB83AidZG644kn5Gtj9Z06ZTTr4CXC1pOgObZj8q\nKP+ymGBml8b1grEw4LSi2Ul5acNh+zjgvPj5EEKrYFNge+BU4F1F6VgG3RY84J4YG26kpC3jj/KW\nmlDSKOBw4BJJvyW4alTa/y7BMlu5H6gv/v9P4GngAOBAYAFwSZvlzSTUqMcAOwAPxm0KoWZRFCcR\n1ucYA4xLbB2BpJ0lHRk/rxf7TvPwYnwRWTx3J4JPaFH8kNBnvYuZvZswQv/jHOctt/6pe/sQfDkX\nmtmfgNUL1K8cyq5iFlyFXw34DnBH3L4NjEnIzya89XaP27kEp+Miyl5CqPont8cJU3M2G4Zr/yVh\nse27gS2BnwGnR9m8BukLaT4BtwGrJPYLHQFupHunbMA3CWuDPBD3NwRuznnuDsDNBCN3M/AAwR+0\nKN3uznOsQZo7gQ0IL5h/EHw5a7J7y77nbd+XshUo8AGPBE5pkuauPMdaLP8k4GhC7WM8YR3YmvPn\n9GG4/lRjD/wI+CihRj+C0HeUea8GUe79wDqJ/bUJE/yTabYiuAHV3GS2A07Imf/3CTWV0r9jDXSb\nQ2guJvuMa64/mdcMjCb0200i9rEBowvU7Zz4gt81bmcD5+Q4bx/gScJI/lmJ47sAV5V9z9u+L2Ur\nUOjFNKlZxLfX5on9zYA7Cyq7kTGdkyYb5vuyhNC8XR63vnhsCbC4zbyPBB4l9PucD/wVOKIuzZ8J\n/YtJw5Cr5pbQ/WVCrbltnQu8r7fXvlfx/+oJg5d5zY2+d0V9F2Neo4F/BS6L2+fzGtRoiNeuO7Y6\nbfj1dcrWbYMWsyVdCfyG0O8DDIgK8iXgBkkPE97MGxN+sEXwkqSD6PdGPxB4paZCQWWkIuk64CMW\n585KWpsw6ft9ZjZkfV5mdq6kqwlx9wC+YmZ/r0u2mpndXjeYlGte5lDqXgCXxgg1a0n6Z+ATwFlR\n1vCaJb0e2IiwZOb2hO8hhFbBakUpZmGGxY+AH0laB3iD5Z91sQ5wrKRJcf8e4DQz+0dR+pVFtxm8\nMYRBiN0Tx4zwhsPMrpe0JfCmKLs/+SWQdBmhL+xqM+tjcBxGmGR9WizzNuDw6Bv3GcXlFJMnNDrW\nBhMsESjAzBZJes25WNJ2hHm2yYnkLYeHklQ/57PmkLqhpA3N7M6EbEEMblDroD8QeGoQZbWke5vP\nsylmdorCOr+LCd+pb5jZdVGcds3vAz4OvIEwsFAzeIuBrxWlWxzV3o9wz2YBT0u6xcw+3+S8aYQo\n4OcBF8TDOwJ/kXSYxalwVaWrHI+bESfRfxrYmX73jNPN7JUofw+hxrcToZZ4rjWesdFK2StNDC94\nsvgs4MNm9ljc3xi43MISjucQ+pDuoX/k1qyNCfiSbsgQm5ntnki7GSGk/juBRYRm72GWY62NdnQf\nyueZo+zUa1ZYJ/gQM7t4CMufbWbbR6fziWb2zTxRZiTdBhxjZrPrjk8BzjCztzc+syKU3aYucqN5\nR/GlhDf+bnE7C/hNg3zWJEzTepzg1nIkTRw3CU7MXyN8yc9JbK8nvCHvJfgy7RC3XYH7Crz2vQir\nlF1ImCr3KPC+KJs/RPd7BDAtR7qR8f/qwLhBltG27q08z5z57k9wxXmeRP9ivC8HZV0zMHMonkki\n/7mE0dZrgbfGY3lGaVPv91B9j4ZzK12Bgh9ys47ilR5Y/TFgXYLz5UzCWgoHE1w8pmcZ1PhDOpkw\nAnpAYjsCuCH+GG5IbFcC+xd8/RMIo2z7EJq4tePnEeKZDcU9n50jzWPxRbAHsVUxiPzb0r3V55kz\n74eAN6fIMg0aYdbPFwkLSa1T2wZRdrOX+4EEF6XT4v5mwO9y5HsvdQMW8fg6FPiCLmsrXYFCLwbu\niP+TBm9O4vNFwE6J/bcTHCtr+5cT4ocdD2xQl/fMLIOaLCdFtwOG+No/DKyZ2F8L+FD8vCuh5nF/\n/BHMJcfbPme5p0TDnmrICJ3xBxH6Uh8Bfg7snDP/lnVv53nmzD/V566ZQSM0ceu3hwdRdtZ3cSTw\n+Raf51EEt6Zd6Hfy3pUQjefoofwOD8dWugKFXkyYn7g5/W4CBxI6rGvyewn9QI/ErS8emxt/TLs1\nyT/VoBL83j7Q5Py9gS8D36htOa/rdfR3vgNsA3yyLs1KBpf+sFAPETqwNyWMTG8MbFxE2fS7jSwj\nh9sIwU/vAmBFzvLb0b3l55kz/58SZqwcQmje7k+stbdr0HKU3ezlfnsbee9DiCK0kDArZwZh1bsh\n/f0Ox9Zto7THEppOW0t6kvAlOzwh3yvlvNrxtWMAzQFY/4hg1mjjccDXJC0l/PgHhDGSdDqhprMb\nwQn0QOD2nNd1HmFWyL/F/QcIP7RkZI1G0wRrz/cZM2t1qcPMsi2n24ikXQjNyb0ItauDcpY/aN2T\nz7CN55mH8YQwTO9NZg9cZmZNp5jFUF3bMDAK9QXpZwygme43S/o54VklXbTupAlm9gfgDzn1qBRd\nOUoraXVChI0lKfL1SXzJgP+fkZ1ZHBFMGXk73MweyaHT3Wa2XeL/GoRaU9PJ2JLuMLO3JsOCS5pj\nZlMSac4BngN+EQ8dS2hCfTyG6F6LMA1qUKuW5Sx7P+DdcXd6/MEk83iEEKHmUkIElxfJSSu6q/Gi\nRYlT23+eOfRejeD4+0YzO6rmDlW7N5K+SWgqbkMIyf9+4CYzOzBn/pm6p4yimyVGz1PyvdTMDoqf\nTzazryRk15rZe9PP7ny6qoansDThAUSfrZrTp5mdGOX7EXyfNiRMpt+YMD9wUqP86jGzh4H3JA2q\npK1j3g3dSxJv1Jfj/5ckbUhoLmyQ89LyTDT/f8DX6Q8KcB39C8WMJRiLlWoi7ZYt6XvAW4Gai8Vx\nCqHLj0/ksZ2ZLc5RViMGrbuZ5XImb/Q8B6OYpDcQBkCmxUM3AseZ2ROEWvEsgkGCMF3rN/TXnA4E\n3kJokh6pEB8vdyDaZrqb2W6DuZYEWyY+70mIVlNjvRbz7Bi6yuARFq55nvBFa+TQexLBJ+tPFnyU\ndiPR5K03mLXjCYPZyKDuR1g854cNyjP6naD/oBBJ9geEKW5GaNrm4V8JI4ybS7qZ8MUbUBOItaaG\nK17lNQAtlv0BYIpFx15J5xNqc0mD96qkY2lhEaF2dG/xeb4mz8G5BCfdj8T9w+OxPQlTGA9WWPgd\nM3tJA6ddvGxmfZKWSxpPeAFPTOie6TSd4+XeaoDRrCZf5ZuD3Wbw3mBmaf10EEIoLZQ0QtIIM7tB\n0k8S8mYGs5H819D8jWpmJ8WPv5P0B8LE/uclLaHxF+m1PkAzuzP2gb0pHr/f+kP4hMShCbNSPma2\ne5OaSCZ5yiY0OZ+Nn9dskE3Liwi1ozutPc/BsJ6ZJZvP50n6XPz8qsIsm1rNePO6MmbGF+BZsfwX\ngFsT8tMI/oKnSmrkNN1M9/No3u/biNUUpryNYOD0NxFq25Wm2wzeLZK2NbO5KfLnYt/ZjcDFkp4m\n0aFLc4OZKVdYeWoTBtYmLkiTS8rd6U9wQaidu0M8N9nB/cXE5zGEt39tvmpWTaTdsr8L3KkwlUmE\nvrz6muYWZvYRSR80s/Ml/YrwDPLQju5tPc8cLJR0OP2rex1Cf3zFbwJ/JATevJhgsD9eO9HMPh0/\nni7pj8B4M7s7If8T8CeFNS8OiZ8fJxjIi3Lo3mqA0acIc3AhRExJBlqtnyNdObrC4EmaR3CNWAU4\nUiE4wFL6a0m16TQfJPSlHU9wIViT/oVuoLnBTJVLupDgEjOHxDqgxPmIafJY20vFzJ5tlndMN6vu\n1Jsl1UaBs2oiNf0bGuscZe9DmFGyiODq0yh4QNNFhDJeFk11z6Dl55mTTxBqnz8m3JPaLA4IDudX\nEYJJPEyolS6onSjpejPbAyAx0PDasbi/LmG5xMMJ3QQXE6ZFHpFD95YCjLbR91cJusLgEaJPTGmW\nqDY6KOkmwqjWrwjV/M1jkp3JNphZ8qmEGQFp/RwN5ZL+SvhSJvt3avtG8JBvljcKETFqjIjn1JqX\nWTWRZsa6Wdm/JIT93i/mMVvSDDP7aSLNmQrRW04g9AeuQRhgyVN+pu5NaOd5NsXCXOC0ha1r92VP\nEvcFOIPgnjQh3pNktJSNaidLupzQjXAhsE/iJXKJpJk5dK/1vW6W1u+bRmyKb2VmdyWOvZHgO/lk\n+pmdT7cYvL9axkR0BReBV81sOYCZvUXSMYQf0UcTSd9PcIytuYrMILh65JHPI8ybTfPjaii3hL9W\nNFpbMtBlJk/eEPpyaoZyGaG29ckoa1QT+Xji3Cyjlll27AedQRip3Y0wZ3USwSm3xoX0d7DXVs16\nXc7ym+meRTvPMxVJ38gQm5mdlHFfAD5H8BSYRf+LbQnhOmucGdNPA6bGl/R/mNkrZjZVIThElu7z\nCTNNXop5X0Hox8vDcuAySdtZvwvR2YS54m7wOoD1Jf1rhvwgwkrsfwdQWJf2C4Tm2GcI7gLENJ8i\nuDyI8EM9i/4vYiO5Yi1tHDA/NiOTnci1L3RDufUvIfkpgvPyGwg1nZ2AFyTd2uzcyFeAP5rZYklf\nJwQoeCnKTiQE5VwUy1qHMCWsNkq6klGT9Pucel9PmCB/K6Ff7q1m9jQDadbBnmVUm+meRSvPMylP\no5Ef4eqEF8y6wElN7stPo9H8Sd3zSg5aHEmYuXJq3D806lfry2ym+wXx/O+mnJ+KmS2LNcyDgHNj\n7W49M5vZ7NyOxzpguke7G+GH8g1CR3Gj7a5E2qMIUTNqS9HNTMjuBlZP7L8WwTZD/r/0zzXcJbEl\nj6XKE3nNJdTsalPVtia8tZueW9Mt/t+ZEJxg71oaGkzwZ+CUpBsIfXDXEJpBVxLWWcij94+jntcR\nVkbbHRhbV1bm/NSU8q/Mo3uTfFt5noOaY0x4IZxA6CI5GVg/z33Jel7xeGagixzX1jRQRpPr2hqY\nET+fAHy2jN920Vu31PCesgzfKUm7KHi2TyS8OfcwswcVZlwkV9gS/X1IxM9qIn/JzKZLGmVmf64r\nd2ztWJo8sfuKmb0iqRYY9D5J62blXXeZNb32JqxFcJWkb8djIyStbQNrScln/y0aYGZ/bla2xYCS\nksYRmprnEmproxOnNOtgb1h+Tt0HIGkD4FkLgVVbeZ4DQhRnlLMOoZ/sMEIzfYeajpDrvmQ9Lwgj\n3zuZ2W0xn7cTpuTl1b3Z+ZnE758kbUXo9qn08ow1usXgNfuSfgQ4htCHcTDwS0k3EvpHvplIdy4h\nsuvlcf9DDPRbaiS/T9JcQufw3Ym04wgjpccQgo42lCf2n1Dwy7oCuE7SIsIobmreddf4pEK48T2B\nkxUcU2vza38I3Krgz1W7H9+pnVhv0AAkHaMwFzOzbEmfIfwYdiT0G55DdDmJuhtNRs8blZ8gU/cG\nXEhwkv4drT3PlfzUJL3eEiPPkn5BmBN8JrCtmb3Q4JzU+xJp+LwS92wU4UXxWNzfmODLmFf3HRPn\nA7wRuL+WvzUYmKm/zpjf2YQV7hbVp68iXTGXVtI6ZvZs85Svpd+QYOzutroIuApTxHaOuzfaypFf\nB8gJLgdrA//OQP+zJRZcStbMkqfotwthhPUWwohm03PjwMxehC/ng7Gms62ZXRvl29A/6+N/zGy+\npJvMbGet7Pxc63fcrlnZkr4Y78Msi4NCCdnGja4vwcVZ5Vt/4IWVdM/KVJIIgyD3DPZ51stjmqvM\nbO/EvhHWK1mepnfWfYl5NHxehDBYqVhicC5L92b33hoM8jW4ztUI3UUHWPALrDxdYfAcx3Hy0Cik\nkOM4TlfS1QZP0lGtyts518vuPt16tew88kpR9jDxUG40X1cgVd7OuV529+nWq2XnkVdp6+oanuM4\nTpKuGrSIo2eO47TBmDFrDNhfsWIZI0eOAmDZsldYvnxZLl/FNPbaay9bsGBB84TArFmzrrH2ItoM\noDJ+eJJeMLM1mqd0HKcdttgifW34hx5quiRGUxYsWMDMmfl8oCVNaLvABJUxeI7jdA9ltSzd4DmO\nM6wYsKJvpaj1w0LlDV4cMu+eYXPH6XoMK2l5jMobPDM7kzCn0QctHKcKGPSV9EutvMFzHKd6eB+e\n4zg9gQF9bvDaZ90JG7Dvh49Old94/RWZ5//vw3OKVslxUmjmylZe78zk7d6ZKnvyb3mjxGfjNTzH\ncXoCM/NRWsdxegev4TmO0zO4W0qLJP3wVl9jzSapHccpmzBoUU7ZlY+WYmZnmtlUM5s6ZsxqZavj\nOE4O8oZzKprK1/Acx6kYPmjhOE6vYPigRSG8sOR5brrh96nyRx/LXOyqY1l11TGZ8ldffSVTvsUW\nO2bKH3poVqZ8xIiRqbK+vhWpMieLzp0Fue0u26bKZtxUvxxya7jjcRM8Fp7jdA9ew3Mcp0fwaCmO\n4/QI5tFSWifph7fKKquWrI3jOHno81Ha1kjGwxszZvXO7Ql2HAfwaCmO4/QYPmhRAEuXvtTUxaKK\nNHM7WW/CxEz5kiUL2yrfXU96i6nvSHdLWX2NAtxSzLyG5zhO7+A1PMdxegIDVrjBcxynV/AanuM4\nPYMbvBbxdWkdp1qYD1q0jq9L6zjVw2t4juP0DG7wnJZ5ZsHjZavgdBHv3TbdD2/82Pb98MIorU8t\ncxynR/DgAY7j9AZDtF5FHjp2ER9Jm0i6V9JZku6RdK2kYsKtOo5TGrUQ72Us4tOxBi+yJfALM5sE\nPAccUJ9A0lGSZkqaOezaOY7TEn3RNaXZVjSd3qT9q5nNiZ9nAZvUJ3C3FMepHj5K25ilic8rAG/S\nOk7FMV+m0XGcXsLXtHBSkdrral1rrfUz5YsW/aNJDulfzrXWel3mmYsXL8iUe6y9zuPauXNTZYtf\nfrmQMtwtpQ4zewSYnNg/pTxtHMcpijIX4u70UdrXkPRI2To4jlMMRbqlSBopabakPzRL27E1PMdx\nupTiBy2OA+4FxjdLWJkaHvBMo4Puh+c41aJIx2NJbwD2Bs7OU3Zlanhm9taU4+6H5zgVYxBOxRPq\nKjNnxt98jZ8AXwbG5cmsMgbPcZzuYRBuKQvMbGojgaR9gKfNbJakXfNk5gbPcZxhp6BB2mnAfpI+\nAIwBxku6yMwOTzuhqwzeWmutz667Hpoqv+KKn2SeP2LEyFTZm970tsxz77331mzl2sDajB22aNHf\nC9JkZZ57LtuHb/Sq2ZNjlr5ajF+XUxznff/XqbKFf3+27fyNQTVp0/MxOx44HiDW8L6YZeygywye\n4zgVwKeWOY7TKwyF47GZTQemN0vXsW4pkk6U9LnE/nckHVemTo7jFIPHw1uZc4B/AlCYTPpR4KL6\nREk/vKVLvT/IcaqAx8Orw8wekbRQ0vbA64DZZrawQbrX/PDWXvt17ofnOB2PebSUFM4GPg68nlDj\ncxyn4pgV5pYyaDrd4F0OnAiMAtL9TSLPPfd0U9eTLLJCFU3adlrmuUPpllJl3O2kekzZfUqqbMaN\nqxVSho/SNsDMXpV0A/CcmXngNMfpAoryw2uFjjZ4cbBiJ+AjZeviOE5xeDy8OiRtAzwEXG9mD5at\nj+M4BZHTJWUojGLH1vDMbD6wWdl6OI4zBHiTtjUkHQUcVbYejuPkp2+FG7yW8Hh4jlMtgluKGzzH\ncXoEN3gdzm8v9UXTnN7gy0celCq79BffL6CEoRmQyIMbPMdxhh0raWFaN3iO4wwr3ofnOE5PYT61\nrDXcLcVxqocHD2gRd0txnIph5n14juP0Dt6H5zhOTzAUa1rkxQ1egkmTdk6V3XPPTcOoieOUx7Vz\n56bKFr9cTHxDN3iO4/QGZtgKH6V1HKdH8Hh4DZB0haRZku6J7ieO43QBtXUtmm1F0+k1vE+Y2bOS\nxgJ3SPpd/cpl7ofnONXCBy3S+aykD8fPE4EtgQEGz/3wHKdi+NSylZG0K/Ae4B1m9pKk6cCYUpVy\nHKcAjD4ftFiJNYFF0dhtTVjMx3GcLsBreCvzR+BfJN0L3A/cNtQFuq+d0wuExQDT2WPSpFTZ+LFj\n2y7fo6U0wMyWAu8vWw/HcYYAN3iO4/QKVk4XXuf64Un6nqRjE/vfkvTFMnVyHKcYylqXtmMNHnAJ\nkAyuf1A8NgBJR0maKWnmsGnmOE7rmNHX15drK5qObdKa2WxJ60vaEFiPMGL7eIN07ofnOBXCHY/T\n+Q1wIPB6GtTuHMepIFbcIj6SxgAzgNHAqsB/mdlX09J3usG7BDgLmADsUrIujuMURXE1vKXA7mb2\ngqRRwE2S3mVmNzZK3NEGz8zukTQOeNLMnipbH8fJy+TJ786Uz5s3Y5g0WZmJE7fOlP/H5f+dKnt6\n0fMFaFDcgISFjF6Iu6OAkcCitPQdbfAAzGzbsnVwHKdY+vI3aSfUDUieGfvtX0PSSGAWsAVwupnN\nS8us4w2e4zjdhQ2uD2+BmU3Nzs9WAFMkrQVcI2k3M7uhUdpOdkvxeHiO06UMhR+emT0HXAWkGsiO\nNniEeHg7Ei7gs5LWrU/gfniOUz2KMniS1os1O2LczD2BOWnpO71J6/HwHKfrKHQWxQbA+QoREUYA\nF5nZdWmJO9bgeTw8x+lSCoyWYmZ3A9vnTd+xBg+Ph+dUGCtrdnwOHn/8vkz5Flu+MVU2ZsyqbZdv\ngK3wmRb11MfDW1qyPo7jFIRPLavD4+E5TpcyRJFQ8tCxBq8eSS+Y2Rpl6+E4TvsUNZd2sFTG4KXh\nyzQ6TvXwGl6LuFuK41QLDw/lOE7vYIYNQXDPPLjBcxxn2CnLa8cNXkGMGjU6U75sWTteNWoi79yW\nfLMlAZuKR0RvAAAM8UlEQVT5q623XrpPGMAzzzw2aJ2Gg/aX/By6Zz5yZPbPfrVV033tRqiZXvnw\nJm0KcZ7coT5C6zhdQonr0nZ68ACAtYBPl62E4zjFUBu08FXLGvM9YHNJcyT9oGxlHMdpF6NvRV+u\nrWg6vkkLfBWYbGZTGgndD89xKkaJTdoqGLxM3A/PcSqIGzzHcXqFkuxdJQzeEmBc2Uo4jlMMPtMi\nAzNbKOlmSfOAq83sS2Xr1Ij2/OyaUd2Wertx4TrVz27oGbpn3swPb/tNNkmVrTY62980FwUuxD1Y\nOt7gAZjZoWXr4DhOURh9PrXMcZxewZu0juP0Dm7wWsP98BynWgxyIe5CqbzBcz88x6ke7pbiOE6P\n4GtaOI7TKxg+Sus4zvCwdOlLmfJxY9LXuy8iHp7hfXiO4/QQ3qR1HKdHMHdLcRynR/DwUK3jfniO\nUz36VrjBawn3w3OcauHRUhzH6R28Ses4Tu/gjse5kHSLmb1zqPLfZptpqbK+vhWZ595331+a5D6U\nD7i669Y2Y/y4dTPlr2bEIXzllRea5J5939TE56zdWH9ZlLnO8dHH/Xuq7NHH/95Guf24wcvBUBo7\nx3GGD3c8zoGkF3xBbsepNmVGS6nCurSZSDpK0kxJM8vWxXGcfBS1ELekiZJukDRf0j2SjstKX6ka\nXiPcLcVxqkahgxbLgS+Y2Z2SxgGzJF1nZvMbJa68wXMcp2IU2KQ1s6eAp+LnJZLuBTYC3OA5jtMZ\nDKKGN6Guu+rM2KpbCUmbANsDqS4TVTN4Q9pkXWWVUamyV155NfPcESOyu0ObubW0R/ZtGTMme5wn\n67oBxo9Pdw156qmHM88dPXq1THkz15ElLyzKlGe5hjRz7Vi+fFnLeQ81EydunSl/+OG72sg9+/vy\n35ddkCp7ftHCNsrtL30QBm+BmU1tlkjSGsDvgM+Z2eK0dJUxeJLWBZ4tWw/HcdrFsAIDgEoaRTB2\nF5vZZVlpK2HwJG0ITAdOKVkVx3HaxaCoyrOCd/gvgXvN7EfN0nesW4qkTSTNAzCzvxFGYrPd7h3H\nqQRFuaUA04CPAbtLmhO3D6QlrkQNLwsPD+U41aMotxQzu4nmcytfo/IGz/3wHKdaeHioxixnYJM7\nfWURx3Gqgxl9K8oZAe/YPjzgH8D6ktaVNBrYp2yFHMcpCLN8W8F0bA3PzJZJOhG4HXgSuG+oy7z7\n7umpskMOPz7z3AceuKNgbYqjeZikbF5o4gs3lGW34wvXXgilcmnPz649jvn611Nlv/jOCYWUYSWF\nLOtYgwdgZqcCp5ath+M4xWEe8dhxnN7BSpvF0sl9eEhaXdJVku6SNE/SwWXr5DhO+xTohzcoOr2G\ntxfwNzPbG0DSmvUJ3A/PcapHX4FTywZDR9fwgLnAnpJOlvQuM3u+PoGZnWlmU/NMMHYcp3xC7a0v\n11Y0HW3wzOwBYAeC4fu2pG+UrJLjOEXgbikrE4MGPGtmF0l6DvhU2To5jtM+7pbSmG2BH0jqA5YB\nx5SlyNw5N5dVtOMMK1PfsW2qbPU1xhZShrulNMDMrpH0F+BQMzutbH0cxykCG+KAuOl0dB9eZC3g\n02Ur4ThOMdQcj8twS6mCwfsesHmMc/WDspVxHKd93A8vna8Ck81sSiOh++E5TvXwPrwW8Xh4jlM1\nhsblJA+VN3iO41QPo5yZFlUweEuAcWUr4ThOMZiVN7Ws4w2emS2UdHNc0OdqM/tSq3lts820TPn8\n+em+dvPmzWi1WMdpQLNlGIauyTd58rsz5TNvnZsqe/GFlwvQYGgGJPLQ8QYPwMwOLVsHx3GKo6zw\nUJUweI7jdBdl1fA62g9P0uGSbo8+eGdIGlm2To7jtI87Htch6c3AwcC06IO3AjisQbqjJM2UNHO4\ndXQcpwXyRkrpMcfjPYAdgTskAYwFnq5P5H54jlMtDOizcubSdrLBE3C+mWUvF+Y4TsXwUdpGXA/8\nl6Qfm9nTktYBxpnZo61mmOV2UmXGj5/QlvyJJ7JXwJw48c2psmeeeTzz3BUrlmXKq7yUYnuU1xhp\n7mJ19JDr4AavDjObL+kE4FpJIwjx8I4FWjZ4juN0Bm7wGmBmlwCXlK2H4zjFEcYj3A/PcZyewDCf\nWtYaHh7KcaqHr2nRIu6W4jjVw/vwHMfpEcz78BzH6Q1qa1qUgRu8LmDJkmcz5YsXL8iUB6+fdJ54\n4v5U2S67fDTz3OnTf5UpbxYmaeTI7OnTq4wclSpb+mp2KKORI7O//itWLM+UO61TlMGTdA6wD/C0\nmU1ulr5j59I6jtO99PX15dpycB6wV95yvYbnOM4wY1BQH56ZzZC0Sd70bvAcxxl2BuGWMqEuEtKZ\n0TOjJSpv8NwPz3GqxSAHLRaY2dSiyq68wXM/PMepHj5K6zhOj1CeH56P0jqOM+wUNUor6dfArcCb\nJD0h6ZNZ6b2Gl5Mtt8zuRnjwwfIizLf7tmzn/OZ+dk1Lz5Q284Vrx1fO/ewas8uu6d/1C05dre38\ni3Q8NrNDBpPeDZ7jOMPM0KxXkQc3eI7jDDuGz6VdCUn/BhxBWLzncWCWmZ1SrlaO47SLj9LWIWlH\n4KPAFIKedwKzGqRzPzzHqRSWd9pY4XSswQPeBVxuZi8BSLqyUSL3w3OcauEh3h3H6SnKatJ2sh/e\nDOBDksZKGgfsW7ZCjuMUg5nl2oqmY2t4ZnanpEuAuwiDFncMdZnrTZiYKnvssflDXbzTkOx4edl+\nfNnnjh+3TqZ88ZKFTcoeOrbeeqdM+X333TZkZf95erpP6ZIlLxVQQnluKZ1cw8PMvmNmW5nZzsAD\nZevjOE4xWM6/ounYGp7jON2JGfT1rSil7I6t4UnaRNK8xKEXgDXK0sdxnKLI13/XU314eXE/PMep\nHu543CLuh+c41cMN3sosZ2CTe0xZijiOUyweD29l/gGsL2ldSaMJS7E5jlN1zPJvBdOxNTwzWybp\nROB24EngvqEu85kFj6fKJk9+d+a58+bNKFodB2gWL6+dc8v0s2tGu352Wd/Xe++9JfPc5a9mxAks\nwAgZ0OdTy1bGzE4FTi1bD8dxisWbtA2QdLik2yXNkXSGpOxl6B3HqQDluaV0rMGT9GbgYGCamU0B\nVgCHNUh3lKSZdWtXOo7Twbgf3srsAewI3CEJYCxhTu0A3C3FcapFkWtaDJZONngCzjez48tWxHGc\nIjHMp5atxPXAgZLWB5C0jqSNS9bJcZwC8OABdZjZfEknANdKGgEsA44FHi1Xs8Zsuul2mfInnrg/\nU75s2dKWyx4xor2xnLImcjtDRztuUqusmmEW1CxcVz68SdsAM7sEuKRsPRzHKRY3eI7j9ARhBNYd\njx3H6RG8htciHh7KcaqHL9PYIu6H5zgVxGt4juP0BobhNTzHcXqAMmdaqKyChwJv0jrO0GNmbTnj\njRgx0kaPHpsr7SuvvDjLzKa2U96AstvNQNJ0SffHiCZzJP02ITtK0n1xu13SzgnZPpJmS7pL0nxJ\nR7eri+M41aBSwQMkrQqMMrMX46HDzGxmXZp9gKOBnc1sgaQdgCskvQ1YSBhoeJuZPREjGm8Sz1vb\nzBa1djmO43Q+Vo1lGiW9WdIPgfuBrZok/wrwJTNbAGBmdwLnE6aHjSMY24VRttTManOvDpY0T9IX\nJK03GP0cx+l8an14HRkPT9Lqko6UdBNwFjAf2M7MZieSXZxo0v4gHpsEzKrLbiYwycyeBa4EHpX0\na0mHxfmymNnpwPuB1YAZkn4raa+avIF+Hg/PcapGSWta5LGwi4GbgK1T5NOBqQ2OPwusWXfsg8Bl\nif1tgc8Ds4HzGuQh4APA34Arc+hqvvnm29BueWtnWb/TkSNXybUBM3Pktxeh1fkQ8NWstHmatAcS\nFtG5TNI3BhGiaT4hgGeSHYF7ajtmNtfMfgzsCRyQTBj7+k4jrGlxKeBx8RynSzDry7U1Iy778AtC\nq3Ab4BBJ22QUnNsqrwscB8wB/gRs0qSGtx9wB7Bu3J8CPAZsAKwB7JpI+x5gXvz8XuBu4FrgIGDV\nwbw5fPPNt6HdiqjhDWLLrOEB7wCuSewfDxyflj73KK2ZLQR+Cvw01r6SwywXS3o5fl5gZu8xsysl\nbQTcEv3jlgCHm9lTksYBX5Z0BvAy8CLw8Xj+QmBfM2sl7t0CBsbLmxCPpZElb+dcL7v7dOvVsuvl\nG2eky8s1Mc88jKnrnz/TwnTSGhsByfVVnwDenppbu9a6kzeavx1S5e2c62V3n269WnYeeZkbocvt\n7MT+x4Cfp6Xv5BDvjuM4zXgSmJjYf0M81hA3eI7jVJk7gC0lbRonRHyU4PLWkG4PHnBmG/J2zvWy\nh0buZXemvDTMbLmkzxD6BUcC55jZPWnpuyp4gOM4ThbepHUcp2dwg+c4Ts/gBs9xnJ7BDZ7jOD2D\nGzzHcXoGN3iO4/QMbvAcx+kZ/g/HdcFxbae9NAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2ba49ffe4c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluateAndShowAttention(test2013[111])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
