# MICA_NeuralMachineTranslation
Team MICA's attempt at NMT

Dataset: English to French
Character Tutorial: https://github.com/nyu-dl/dl4mt-c2c
General Tutorial: https://github.com/nyu-dl/dl4mt-tutorial

## Todo: 
- Data Processing https://wit3.fbk.eu/mt.php?release=2016-01 : Eduardo
  - Both models: BPE on source
  - Model 1 Target: Use BPE
  - Model 2 Target: Does not use BPE

- Model 1: Encoder-Decoder With Attention & BPE 
  - Adapt from Theano to pytorch : Akash

- Model 2: Character-level Decoder 
  - Adapt from Theano to pytorch : Millie

- Next meeting: Thursday 

